{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Margin Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From logistic regression\n",
    "\n",
    "The sigmoid function\n",
    "\n",
    "$ h_{\\theta}(x) = g(z) = \\frac{1}{1+e^{-\\theta^T x}}$\n",
    "\n",
    "Where $z = \\theta^T x$\n",
    "\n",
    "In Logistic Regression:\n",
    "- If $y=1$  $\\rightarrow$ $h_\\theta(x) \\approx 1$, $(\\theta^T x) \\gg 0$\n",
    "- If $y=0$  $\\rightarrow$ $h_\\theta(x) \\approx 0$, $(\\theta^T x) \\ll 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost of an example $(x, y)$: \n",
    "$$-(y\\;log\\:h_{\\theta}(x) + (1-y)\\:log(1-h_{\\theta}(x)))$$\n",
    "Substituting $h_{\\theta}(x)$\n",
    "$$-y\\;log\\:\\frac{1}{1+e^{-\\theta^T x}} - (1-y)\\:log(1-\\frac{1}{1+e^{-\\theta^T x}})$$\n",
    "\n",
    "1. When $y=1$: $-y\\;log\\:\\frac{1}{1+e^{-\\theta^T x}} - 0$\n",
    "2. When $y=0$: $0 - log(1-\\frac{1}{1+e^{-\\theta^T x}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going into SVM:\n",
    "\n",
    "- Improve cost function of logistic regression:\n",
    "    - y = 1 $\\rightarrow$ $\\text{cost}_1(z) $\n",
    "        - Flat part (cost = 0) for z > 1\n",
    "        - Straight line for z < 1\n",
    "    - y = 0 $\\rightarrow$ $\\text{cost}_0(z) $\n",
    "        - Flat part (cost = 0) for z < -1\n",
    "        - Straight line for z > -1\n",
    "    \n",
    "- Provide a computational advantageous method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function:\n",
    "\n",
    "__LR__:\n",
    "\n",
    "$$ J(\\theta) = -\\left[ \\frac{1}{m} \\sum\\limits^m_{(i=1)} y^{(i)} log\\:h_\\theta(x^{(i)}) + (1-y^{(i)})\\:log(1-h_\\theta(x^{(i)})\\: )  \\right] + \\frac{\\lambda}{2m} \\sum\\limits^n_{j=1}\\theta_j^2 $$\n",
    "\n",
    "$$ J(\\theta) = \\left[ \\frac{1}{m} \\sum\\limits^m_{(i=1)} y^{(i)} \\left(-log\\:h_\\theta(x^{(i)})\\right) + (1-y^{(i)})\\:\\left(- log(1-h_\\theta(x^{(i)})\\: )\\right)  \\right] + \\frac{\\lambda}{2m} \\sum\\limits^n_{j=1}\\theta_j^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SVM__:\n",
    "\n",
    "$ J(\\theta) = \\left[ \\frac{1}{m} \\sum\\limits^m_{(i=1)} y^{(i)} \\text{cost}_1(\\theta^T x) + (1-y^{(i)})\\:\\text{cost}_0(\\theta^T x)\\:   \\right] + \\frac{\\lambda}{2m} \\sum\\limits^n_{j=1}\\theta_j^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-organising the above:\n",
    "\n",
    "$$ J(\\theta) = \\left[\\sum\\limits^m_{(i=1)} y^{(i)} \\text{cost}_1(\\theta^T x) + (1-y^{(i)})\\:\\text{cost}_0(\\theta^T x)\\:   \\right] + \\frac{\\lambda}{2} \\sum\\limits^n_{j=1}\\theta_j^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J(\\theta) = A + \\lambda B $$\n",
    "\n",
    "Re-organising the regularization structure:\n",
    "\n",
    "$$ J(\\theta) = \\textbf{C} A + B $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J(\\theta) = \\textbf{C} \\left[\\sum\\limits^m_{(i=1)} y^{(i)} \\text{cost}_1(\\theta^T x) + (1-y^{(i)})\\:\\text{cost}_0(\\theta^T x)\\:   \\right] + \\frac{1}{2} \\sum\\limits^n_{j=1}\\theta_j^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "$$\n",
    "h_{\\theta}(x) = \\begin{cases} \n",
    "1 & \\mbox{if } \\theta^T x \\geq 0 \\\\ \n",
    "0 & \\mbox{otherwise }\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Margin Intuition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVNs are refered as large margin classifiers. Limits are in 1 and -1 for positive and negative classifications, respectively.\n",
    "\n",
    "![title](pictures/svm_largeMargin.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVNs add a margin to decision boundaries, adding robustness to the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_decisionBoundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVN can be robust to outliers when $\\textbf{C}$, the regularization parameter is adequately tunned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_outliers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math of Large Margin Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_mathInnerProduct.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_mathDecisionBoundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_mathDecisionBoundary2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landmarks & Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity or Kernel function. The function can also be rewritten for $n$ dimensional vectors ($n$ features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_kernel2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example__ with two features ($n = 2$)\n",
    "\n",
    "Height of surface equal to $f_1$ (distance to first landmark $l^{(1)}$):\n",
    "\n",
    "- $f_1 = 1$ when $x = l$\n",
    "- $f_1 \\approx 0$ when $x$ far from $l$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma$ is the Gaussian Kernel. It controls how quickly the height of the landmark decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_gaussianKernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options:\n",
    "\n",
    "- Landmark per training example. $l^{(1)} = x^{(1)},\\: ..., l^{(m)} = x^{(m)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landmark per training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_landmarkPerExample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note again that the regularization parameter is not summed over $\\theta_0$. \n",
    "\n",
    "The regularization parameter can be rewritten as follows: \n",
    "$$\\sum_j \\theta^2_j = \\theta^T\\theta$$\n",
    "However, some SVM implementations have the following variation:\n",
    "$$\\sum_j \\theta^2_j = \\theta^T\\textbf{M}\\theta$$\n",
    "Where $\\textbf{M}$ is a matrix which tunnes the distance measure, depending on the Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_trainingKernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance & Bias in SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing parameters $\\textbf{C}$ and $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_parameters.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using an SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a standard library! However still need to select:\n",
    "\n",
    "- Parameter __C__\n",
    "- Choice of Kernel\n",
    "    - If no Kernel, (\"linear kernel\", $y=1$ if $\\theta^Tx \\geq 0$). \n",
    "        - Useful when $n$ is large & $m$ is small.\n",
    "    - Gaussian Kernel.\n",
    "        - Choose $\\sigma^2$. Useful when $n$ is large & $m$ is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May need to provide __Kernel__\n",
    "\n",
    "## Providing a Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_provideKernel.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choices of Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They __MUST__ comply with __Mercer´s Theorem__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_otherKernels.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification with SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__One VS all__: Train K SVMs & predict class with largest $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_multiClassClassification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression VS SVNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $n$ is large relative to $m$ ($n = 10000, m = 10 - 1000$):\n",
    "    - Logistic regression or SVN with linear kernel\n",
    "- $n$ is small relative to $m$ ($n = 1-1000, m = 10 - 10000$):\n",
    "    - SVN with Gaussian kernel\n",
    "- $n$ is small, $m$ is large ($n = 1-1000, m = 50000 + $):\n",
    "    - Create/add more features, then Logistic regression or SVN with linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/svm_logisticVsSvms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
