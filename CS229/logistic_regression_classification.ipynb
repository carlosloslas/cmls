{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "Classification algorithm\n",
    "1. Binary Classfication\n",
    "\n",
    "    $ y \\in \\{0, 1\\}$\n",
    "\n",
    "    * 0: 'Negative Class'\n",
    "    * 1: 'Positive Class'\n",
    "\n",
    "2. Multi-Class Classification \n",
    "\n",
    "    $ y \\in \\{0, 1, 2, ..., n\\}$\n",
    "\n",
    "    * 0: 'Class  0'\n",
    "    * 1: 'Class  1'\n",
    "    * 2: 'Class  2'\n",
    "    * ...\n",
    "    * n: 'Class  n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model\n",
    "\n",
    "It is required that $ 0 \\leq h_\\theta(x) \\leq 1 $\n",
    "\n",
    "Our linear regression hypothesis was $ h_\\theta(x) = \\theta^T \\underline{X} $\n",
    "\n",
    "The logistic regression hypothesis is $ h_\\theta(x) = g(\\theta^T \\underline{X}) $\n",
    "\n",
    "Where $g(z) = \\frac{1}{1+e^{-z}}$ is the Sigmoid or Logistic function\n",
    "\n",
    "The hypothesis is:\n",
    "\n",
    "$$ h_\\theta(x) = \\frac{1}{1+e^{-\\theta^T \\underline{X}}} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of the results\n",
    "\n",
    "$h_\\theta(x) = $ estimated probability that $y=1$ on input $x$\n",
    "\n",
    "$$ h_\\theta(x) = P(y=1|x;\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since\n",
    "\n",
    "$$ P(y=0|x;\\theta) + P(y=1|x;\\theta) = 1$$\n",
    "\n",
    "The probability that $y=0$ on input x is :\n",
    "\n",
    "$$ P(y=0|x;\\theta) = 1 - P(y=1|x;\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group variables in more than two classes. Apply one vs all methodoogy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out classification on each of the groups & distinguish it against the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class $i$ vs rest $\\rightarrow$ $h_\\theta^{(i)} = P(y=i|x;\\theta) \\;\\;\\; (i=1,2, ...)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interrogating the classifier with $x$, take the class $i$ which has largest output. \n",
    "\n",
    "$max\\;h_\\theta^{(i)}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an attempt to avoid underfitting, the order of magnitude of cost function is increassed. This can be overdone and cause the model to __overfit__ or to have a __high variance__ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function too many features. Fits traiing set very well & fails to generalize to a new example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concept is aplicable to linear as well as logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When higher order feature models, not trivial to visualise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Options__:\n",
    "\n",
    "1. Reduce number of features\n",
    "    - Manually select\n",
    "    - Model selection algorithm\n",
    "    - (reducing ammount of information... not a desirable effect)\n",
    "2. Regularization\n",
    "    - Keep features, reduce magnitude/ values of parameters $\\theta_j$\n",
    "    - Works well with multi-feature problems, when reducing not appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller values for parameters\n",
    "- Simpler hypothesis (smoother curves)\n",
    "- Less prone to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify cost fucntion to have a regularization term:\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum\\limits_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda\\sum\\limits_{i=1}^n \\theta^2_j$$\n",
    "\n",
    "Where $\\lambda$ is the regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by convention $\\theta_0$ is not regularised. Regularization sumatory starts at $\\theta_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization parameter, $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carries out the tradeof between:\n",
    "- Fit well the training set\n",
    "- Maintain small parameters to avoid overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\lambda$ is too large, the fit will be a straight line, resulting in an underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gradient descent__\n",
    "\n",
    "Repeat {\n",
    "\n",
    "$ \\theta_0 := \\theta_0 - \\alpha\\frac{\\partial}{\\partial\\theta_0} J(\\theta)$\n",
    "\n",
    "$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial\\theta_0} J_{regularized}(\\theta) \\;\\; (j = 1, 2, ..., n)$\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat {\n",
    "\n",
    "$ \\theta_0 := \\theta_0 - \\alpha\\frac{1}{m}\\sum\\limits^m_{i=1} (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)}$\n",
    "\n",
    "$ \\theta_j := \\theta_j - \\alpha \\left[ \\frac{1}{m}\\sum\\limits^m_{i=1} (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} + \\frac{\\lambda}{m}\\theta_j \\right] \\;\\; (j = 1, 2, ..., n)$\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat {\n",
    "\n",
    "$ \\theta_0 := \\theta_0 - \\alpha\\frac{1}{m}\\sum\\limits^m_{i=1} (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)}$\n",
    "\n",
    "$ \\theta_j := \\theta_j(1 - \\alpha\\frac{\\lambda}{m}) -\\alpha \\frac{1}{m}\\sum\\limits^m_{i=1} (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}   \\;\\; (j = 1, 2, ..., n)$\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(1 - \\alpha\\frac{\\lambda}{m}) < 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized normal equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normal equation__ \n",
    "\n",
    "$$ X = \\begin{bmatrix}\n",
    "    (x^{(1)})^T\\\\\n",
    "    \\vdots\\\\\n",
    "    (x^{(m)})^T\n",
    "\\end{bmatrix}\n",
    "\\;\\;\\; \n",
    "y = \\begin{bmatrix}\n",
    "    y^{(1)}\\\\\n",
    "    \\vdots\\\\\n",
    "    y^{(m)}\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $X$ is a $(m\\times(n+1))$ matrix and $y$ is a $(m\\times 1)$ vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\min\\limits_\\theta J(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\theta = \\left( X^TX + \\lambda \\underline{R} \\right)^{-1} X^Ty $$\n",
    "\n",
    "Where the regularization matrix $\\underline{R}$ is a $((n+1)\\times(n+1))$ like:\n",
    "\n",
    "$$ R = \\begin{bmatrix}\n",
    "    0 & 0 & \\dots & 0\\\\\n",
    "    0 & 1 & \\dots & 0\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & \\dots & 1\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware of non-inversible matrices when $m\\leq n$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cost funciton for logistic regression__\n",
    "\n",
    "$ J(\\theta) = -\\left[ \\frac{1}{m} \\sum\\limits^m_{(i=1)} y^{(i)} log\\:h_\\theta(x^{(i)}) + (1-y^{(i)})\\:log(1-h_\\theta(x^{(i)})\\: )  \\right] $\n",
    "\n",
    "__Regularized cost funciton for logistic regression__\n",
    "\n",
    "$ J(\\theta) = -\\left[ \\frac{1}{m} \\sum\\limits^m_{(i=1)} y^{(i)} log\\:h_\\theta(x^{(i)}) + (1-y^{(i)})\\:log(1-h_\\theta(x^{(i)})\\: )  \\right] + \\frac{\\lambda}{2m} \\sum\\limits^n_{j=1}\\theta_j^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gradient descent__\n",
    "\n",
    "\n",
    "Repeat {\n",
    "\n",
    "$ \\theta_0 := \\theta_0 - \\alpha\\frac{1}{m}\\sum\\limits^m_{i=1} (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)}$\n",
    "\n",
    "$ \\theta_j := \\theta_j - \\alpha \\left[ \\frac{1}{m}\\sum\\limits^m_{i=1} (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} + \\frac{\\lambda}{m}\\theta_j \\right] \\;\\; (j = 1, 2, ..., n)$\n",
    "\n",
    "}\n",
    "\n",
    "However for logistic regression $h_\\theta(x) = \\frac{1}{1+e^{-\\theta^T\\underline{X} }}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
